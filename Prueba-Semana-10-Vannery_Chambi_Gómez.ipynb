{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "Spark = SparkSession.builder.appName(\"vanne\").getOrCreate()\n",
    "SparkContext = Spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio uno**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 'Rugby']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rdd_lenguajes= SparkContext.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
    "lenguajes_r = rdd_lenguajes.filter(lambda x: 'R' in x)\n",
    "lenguajes_r.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio dos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 22, 24, 26, 28, 30]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_pares = SparkContext.parallelize(range(20, 31)).filter(lambda x: x % 2 == 0)\n",
    "rdd_pares.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenga una lista compuesta por los números pares en el intervalo [20;30] y sus respectivas raíces cuadradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 4.47213595499958, 22, 4.69041575982343, 24, 4.898979485566356, 26, 5.0990195135927845, 28, 5.291502622129181, 30, 5.477225575051661]\n"
     ]
    }
   ],
   "source": [
    "rdd_pares = SparkContext.parallelize(range(20, 31)).filter(lambda x: x % 2 == 0)\n",
    "rdd_pares_sqrt= rdd_pares.flatMap(lambda x: [x, x ** 0.5])\n",
    "resultado = rdd_pares_sqrt.collect()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eleve el número de particiones del RDD sqrt a 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30,\n",
       " 5.477225575051661,\n",
       " 26,\n",
       " 5.0990195135927845,\n",
       " 24,\n",
       " 4.898979485566356,\n",
       " 20,\n",
       " 4.47213595499958,\n",
       " 22,\n",
       " 4.69041575982343,\n",
       " 28,\n",
       " 5.291502622129181]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_pares= SparkContext.parallelize(range(20, 31)).filter(lambda x: x % 2 == 0)\n",
    "rdd_pares_sqrt = rdd_pares.flatMap(lambda x: [x, x ** 0.5])\n",
    "rdd_pares_sqrt = rdd_pares_sqrt.repartition(20)\n",
    "rdd_pares_sqrt.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disminuir el número de particiones luego de haberlo establecido en 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 5.477225575051661, 26, 5.0990195135927845, 20, 4.47213595499958, 22, 4.69041575982343, 28, 5.291502622129181, 24, 4.898979485566356]\n"
     ]
    }
   ],
   "source": [
    "rdd_pares_sqrt = rdd_pares_sqrt.coalesce(10)\n",
    "resultado = rdd_pares_sqrt.collect()\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio tres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, 52.3),\n",
       " (1005, 20.8),\n",
       " (1001, 10.1),\n",
       " (1004, 52.7),\n",
       " (1005, 20.7),\n",
       " (1002, 85.3),\n",
       " (1004, 20.9)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_transacciones = SparkContext.parallelize([\n",
    "    (1001, 52.3),\n",
    "    (1005, 20.8),\n",
    "    (1001, 10.1),\n",
    "    (1004, 52.7),\n",
    "    (1005, 20.7),\n",
    "    (1002, 85.3),\n",
    "    (1004, 20.9)\n",
    "])\n",
    "\n",
    "# Ejecutar y mostrar el contenido del RDD\n",
    "rdd_transacciones.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1001, 62.4), (1002, 85.3), (1004, 73.6), (1005, 41.5)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_monto_total_por_cuenta = rdd_transacciones.reduceByKey(lambda x, y: x + y)\n",
    "rdd_monto_total_por_cuenta.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData_Lunes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
