{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "Spark = SparkSession.builder.appName(\"Day\").getOrCreate()\n",
    "SparkContext = Spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Ejercicio 1\n",
    "#Creando RDD llamado lenguajes\n",
    "lenguajes = SparkContext.parallelize([\"Python\", \"R\", \"C\", \"Scala\", \"Rugby\", \"SQL\"])\n",
    "\n",
    "#Filtrar lenguajes con la letra R\n",
    "lenguajes_R = lenguajes.filter(lambda x: x.startswith(\"R\"))\n",
    "print(\"Los lenguajes que inician con la letra 'R' son : \", lenguajes_R.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Ejercicio 2 - A\n",
    "# Creando RDD llamado pares con rango de 20 a 31 porque si no, no toma el 30\n",
    "# El 2 es porque irá de 2 en 2, osea pares\n",
    "pares = SparkContext.parallelize(range(20, 31, 2))\n",
    "\n",
    "# Obtener una lista compuesta por los números pares en el intervalo [20;30] y sus respectivas raíces cuadradas\n",
    "pares_raices = pares.map(lambda x: (x, math.sqrt(x))).collect()\n",
    "\n",
    "#\n",
    "print(\"Números pares y su raiz cuadrada:\")\n",
    "for numeritos in pares_raices:\n",
    "    print(numeritos)\n",
    "\n",
    "#En este caso use flatmap para mostrarlo como sin los () y la formula de raiz cuadrada\n",
    "pares_raices2 = pares.flatMap(lambda x: (x, x ** 0.5))\n",
    "print(\"\\nRaiz Cuadrada de otra forma:\")\n",
    "print(pares_raices2.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Ejercicio 2 - B\n",
    "# Reducir el número de particiones a 20, en este caso no afecta porque la cantidad de datos es poca, pero si está definido\n",
    "pares_raices2 = pares_raices2.coalesce(20)\n",
    "\n",
    "# Recoger los resultados\n",
    "resultados_pares_raices2 = pares_raices2.collect()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Números pares y su raiz cuadrada:\")\n",
    "for numeritos in resultados_pares_raices2:\n",
    "    print(numeritos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Ejercicio 2 - C\n",
    "ejercicio2_c = \" Se podría usar repartition() que tambien  también puede reducir el número de particiones \\n Aunque no es tan eficiente como coalesce() cuando el objetivo es disminuir el número de particiones, \\n especialmente si el número actual de particiones es mayor que el número deseado de particiones \"\n",
    "print(ejercicio2_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Ejercicio 3\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear o obtener la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"TotalPorCuenta\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Ruta al archivo de datos\n",
    "filepath = 'transacciones'\n",
    "\n",
    "# Cargar el archivo de texto\n",
    "lines = sc.textFile(filepath)\n",
    "\n",
    "# Función para convertir cada línea en una tupla (número de cuenta, monto)\n",
    "def parse_line(line):\n",
    "    parts = line.strip().strip('()').split(',')\n",
    "    account = int(parts[0])\n",
    "    amount = float(parts[1])\n",
    "    return (account, amount)\n",
    "\n",
    "# Crear el RDD de clave-valor\n",
    "transactions = lines.map(parse_line)\n",
    "\n",
    "# Sumar los montos por cuenta\n",
    "total_por_cuenta = transactions.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Mostrar los resultados\n",
    "for cuenta, total in total_por_cuenta.collect():\n",
    "    print(f\"Cuenta: {cuenta}, Total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
