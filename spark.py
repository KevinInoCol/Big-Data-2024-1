# -*- coding: utf-8 -*-
"""Spark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z0cz4v5a9bg0nsWva2WVzobN3xOf4VNo
"""

# Instalar SDK Java 8
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# Descargar Spark 3.4.3
!wget -q -P . https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz

# Descomprimir el archivo descargado de Spark
!tar xf spark-3.4.3-bin-hadoop3.tgz

# Establecemos las variables de entorno
import os

os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.4.3-bin-hadoop3"

# Instalamos la librería findspark para facilitar el uso de Apache Spark en un entorno interactivo como Jupyter notebooks o shells interactivos de Python.
!pip install -q findspark

# Instalar pyspark
!pip install -q pyspark

import findspark

findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

spark

#Esta Celda la ejecutan en otro Google Colab para que puedan verificar el cambio de nombre de la sesión de Spark.
import findspark

findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder.master("local[*]").appName('CERTUS Pyspark - Kevin Inofuente').getOrCreate()

spark

"""# Primer Trabajo"""

#Crear
data = [("Spark", "Python")] * 10
df = spark.createDataFrame(data, ["Columna 1 Big Data", "Columna 2 Big Data"])

# Mostrar
df.show()

"""# Segundo Trabajo"""

#Crear
data = [("Spark", "Explora Python es un lenguaje versátil")] * 10
df = spark.createDataFrame(data, ["Columna 1 Big Data", "Columna 2 Big Data"])

# Mostrar
df.show(truncate=False)

