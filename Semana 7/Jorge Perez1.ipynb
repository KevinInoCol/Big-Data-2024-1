{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHsd1glqTyIfhD6SR8j/CD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"aY23BRoX8PPf","executionInfo":{"status":"ok","timestamp":1715570082739,"user_tz":300,"elapsed":18909,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}}},"outputs":[],"source":["# Instalamos SDK Java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","source":["# Descargar Spark 3.4.3\n","!wget -q -P . https://archive.apache.org/dist/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz"],"metadata":{"id":"IshXAR16FZ7E","executionInfo":{"status":"ok","timestamp":1715570108943,"user_tz":300,"elapsed":16229,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Descomprimir el archivo descargado de Spark\n","!tar xf spark-3.4.3-bin-hadoop3.tgz"],"metadata":{"id":"wr3WmxeI8ks8","executionInfo":{"status":"ok","timestamp":1715570114779,"user_tz":300,"elapsed":5843,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Establecemos las variables de entorno\n","import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.3-bin-hadoop3\""],"metadata":{"id":"eBiXd07i8nl9","executionInfo":{"status":"ok","timestamp":1715570127663,"user_tz":300,"elapsed":6,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Instalamos la librería findspark para facilitar el uso de Apache Spark en un entorno interactivo como Jupyter notebooks o shells interactivos de Python.\n","!pip install -q findspark"],"metadata":{"id":"sGl5urw98riE","executionInfo":{"status":"ok","timestamp":1715570144367,"user_tz":300,"elapsed":7382,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Instalar pyspark\n","!pip install -q pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYObNWJu8wCU","executionInfo":{"status":"ok","timestamp":1715570203795,"user_tz":300,"elapsed":53592,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}},"outputId":"64c5182e-f98e-413b-dd23-6b64d05e5411"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import findspark\n","\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"QvB2bswF9pd1","executionInfo":{"status":"ok","timestamp":1715570395961,"user_tz":300,"elapsed":8339,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}},"outputId":"8fd62e75-1255-482d-a73f-bac2d16db11c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7acd7c9c1000>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d4b6997a8676:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Importar SparkSession\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import lit\n","\n","# Crear una SparkSession\n","spark = SparkSession.builder \\\n","    .appName(\"Prueba de Spark\") \\\n","    .getOrCreate()\n","\n","# Crear un DataFrame con los datos especificados\n","data = [(\"Spark\", \"Pyhton\")] * 10  # Repetir (\"Spark\", \"Python\") 10 veces\n","df = spark.createDataFrame(data, [\"COLUMNA 1 BIG DATA\", \"COLUMNA 2 BIG DATA\"])\n","\n","# Mostrar el DataFrame\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jB3zlrTL9urm","executionInfo":{"status":"ok","timestamp":1715570416356,"user_tz":300,"elapsed":9330,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}},"outputId":"97d3c60a-00f0-485f-df86-0bf4d8d447bd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+------------------+\n","|COLUMNA 1 BIG DATA|COLUMNA 2 BIG DATA|\n","+------------------+------------------+\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","|             Spark|            Pyhton|\n","+------------------+------------------+\n","\n"]}]},{"cell_type":"code","source":["# Importar SparkSession\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import lit\n","\n","# Crear una SparkSession\n","spark = SparkSession.builder \\\n","    .appName(\"Prueba de Spark\") \\\n","    .getOrCreate()\n","\n","# Crear un DataFrame con los datos especificados\n","data = [(\"Spark\", \"Explora Pyhton es un lenguaje versatil\")] * 10  # Repetir (\"Spark\", \"Python\") 10 veces\n","df = spark.createDataFrame(data, [\"COLUMNA 1 BIG DATA\", \"COLUMNA 2 BIG DATA\"])\n","\n","# Mostrar el DataFrame\n","df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b-Sd-qD9yIv","executionInfo":{"status":"ok","timestamp":1715570421873,"user_tz":300,"elapsed":334,"user":{"displayName":"JORGE EDUARDO PEREZ NAVARRO","userId":"11340472960425356854"}},"outputId":"8f291530-ad56-44f9-f4b9-347db7e1208d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------+--------------------------------------+\n","|COLUMNA 1 BIG DATA|COLUMNA 2 BIG DATA                    |\n","+------------------+--------------------------------------+\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","|Spark             |Explora Pyhton es un lenguaje versatil|\n","+------------------+--------------------------------------+\n","\n"]}]}]}