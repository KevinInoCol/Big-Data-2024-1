{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2Cpm5SqosemRIfqXCuI8W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiriamBriones/Big-Data-2024-1/blob/main/prueba2_miriambriones_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos pyspark y py4j\n",
        "!pip install pyspark py4j\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "Spark = SparkSession.builder.appName(\"cjqm\").getOrCreate()\n",
        "SparkContext = Spark.sparkContext\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65roiDw4F4Wj",
        "outputId": "cfd5bdc9-4ed0-4249-b035-b68748d286f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=53fd05410c91520ba2488e2956213d0fa8f7a94abb3495472b812db876dff331\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL."
      ],
      "metadata": {
        "id": "IVcaN4Y8H9NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL.\n",
        "lenguajes = sc.parallelize(['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL' ])\n",
        "# Mostrar los elementos del RDD lenguajes\n",
        "(\"Lenguajes de programación:\", lenguajes.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF11zbboIvci",
        "outputId": "4ec2d82d-17d5-4541-aacf-4d1fc10f687a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Lenguajes de programación:', ['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL'])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2: Cree un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R."
      ],
      "metadata": {
        "id": "U24i2f3-JAh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R.\n",
        "rdd_r = lenguajes.filter(lambda x: x.startswith('R'))\n",
        "rdd_r.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmdzfMLTIlRL",
        "outputId": "7246a0db-26ae-451c-e9bd-25c1669c4b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['R', 'Rugby']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30]."
      ],
      "metadata": {
        "id": "Y6-_XjhcVHW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cree un RDD llamado pares que contenga los números pares existentes en el intervalo [20;30].\n",
        "pares = sc.parallelize([20, 21, 22, 23 , 24, 25, 26, 27, 28 ,29, 30]).filter(lambda x: x % 2 == 0)\n",
        "\n",
        "pares.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlY-yNSEVNcH",
        "outputId": "97fed10a-131a-46fc-f8d9-901bc535d303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20, 22, 24, 26, 28, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1: Obtenga una lista compuesta por los números pares en el intervalo [20;30] y sus respectivas raíces cuadradas. Un ejemplo del resultado deseado para el intervalo [50;60] sería la lista [50, 7.0710678118654755, 52, 7.211102550927978, 54, 7.3484692283495345, 56, 7.483314773547883, 58, 7.615773105863909, 60, 7.745966692414834]"
      ],
      "metadata": {
        "id": "7XwmJl5rVh1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeros_pares = [x for x in range(20, 31) if x % 2 == 0]\n",
        "pares_rdd = sc.parallelize(numeros_pares)\n",
        "pares_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "694wJUl1aKUb",
        "outputId": "2e96a1c9-b03a-425d-8aa0-7746ce43849d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20, 22, 24, 26, 28, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2: Eleve el número de particiones del RDD sqrt a 20.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pYrypmTGa744"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Elevar el número de particiones del RDD 'pares_con_raiz' a 20\n",
        "pares_rdd = pares_rdd.repartition(20)\n",
        "\n",
        "# Verificar el número de particiones\n",
        "pares_rdd.getNumPartitions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg1umbiU1GbR",
        "outputId": "e06478ff-9b1d-466b-89f2-e190083f87c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3: Si tuviera que disminuir el número de particiones luego de haberlo establecido en 20, ¿qué función utilizaría para hacer más eficiente su código?"
      ],
      "metadata": {
        "id": "y_hnSiSm8NYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Disminuir el número de particiones a 10\n",
        "#Es la opción más adecuada cuando se desea reducir el número de particiones de un RDD ya que minimiza la sobrecarga de la red y el procesamiento, lo que conduce a una ejecución más rápida y eficiente.\n",
        "rdd_10_particiones = rdd_20_particiones.coalesce(10)\n",
        "\n"
      ],
      "metadata": {
        "id": "JKHK_zDG8TWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Cree un RDD del tipo clave valor a partir de los datos adjuntos como recurso a esta lección."
      ],
      "metadata": {
        "id": "lLsEMnSJAf4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar PySpark (solo necesario en Google Colab)\n",
        "!pip install pyspark\n",
        "\n",
        "# Importar las clases necesarias\n",
        "from pyspark import SparkContext\n",
        "\n",
        "\n",
        "# Crear el RDD rdd_transacciones\n",
        "rdd_transacciones = sc.parallelize([\n",
        "    (1001, 52.3),\n",
        "    (1005, 20.8),\n",
        "    (1001, 10.1),\n",
        "    (1004, 52.7),\n",
        "    (1005, 20.7),\n",
        "    (1002, 85.3),\n",
        "    (1004, 20.9)\n",
        "])\n",
        "\n",
        "# Ejecutar y mostrar el contenido del RDD\n",
        "rdd_transacciones.collect()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNmV_SyMAiYa",
        "outputId": "e0d8fc4c-ed0a-4e29-c2ed-b4fe377509c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1001, 52.3),\n",
              " (1005, 20.8),\n",
              " (1001, 10.1),\n",
              " (1004, 52.7),\n",
              " (1005, 20.7),\n",
              " (1002, 85.3),\n",
              " (1004, 20.9)]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el monto total por cada cuenta utilizando reduceByKey()\n",
        "rdd_monto_total_por_cuenta = rdd_transacciones.reduceByKey(lambda x, y: x + y)\n",
        "\n",
        "# Mostrar el contenido del RDD con el monto total por cuenta\n",
        "rdd_monto_total_por_cuenta.collect()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA1KFiDuLAZL",
        "outputId": "46616cec-a846-472f-ddf5-786c26e33e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1001, 62.4), (1005, 41.5), (1004, 73.6), (1002, 85.3)]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    }
  ]
}