{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalamos pyspark y py4j\n",
        "!pip install pyspark py4j\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "Spark = SparkSession.builder.appName(\"machin\").getOrCreate()\n",
        "SparkContext = Spark.sparkContext\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65roiDw4F4Wj",
        "outputId": "b7afb196-7654-43d7-ab57-db39b26eda40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=e3ca246b1682b1a18ef708d098a450b58ff4dd8da5f56822b5aa88d0177c8a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: Cree un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL."
      ],
      "metadata": {
        "id": "IVcaN4Y8H9NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un RDD llamado lenguajes que contenga los siguientes lenguajes de programación: Python, R, C, Scala, Rugby y SQL.\n",
        "lenguajes = sc.parallelize(['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL' ])\n",
        "lenguajes.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF11zbboIvci",
        "outputId": "b1fec949-be5c-48fc-9ea1-8574eb0e50c3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Python', 'R', 'C', 'Scala', 'Rugby', 'SQL']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2: Cree un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R."
      ],
      "metadata": {
        "id": "U24i2f3-JAh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un nuevo RDD que solo contenga aquellos lenguajes de programación que comiencen con la letra R.\n",
        "rdd_r = lenguajes.filter(lambda x: x.startswith('R'))\n",
        "rdd_r.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmdzfMLTIlRL",
        "outputId": "dc9a525f-4321-41cd-ebeb-04026e9edd0b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['R', 'Rugby']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear un RDD llamado pares que contenga los numeros pares existentes en el intervalos[20;30]\n",
        "\n",
        "# Crear el RDD con los números en el rango [20;30]\n",
        "numeros = sc.parallelize(range(20, 31))\n",
        "pares = numeros.filter(lambda x: x % 2 == 0)\n",
        "pares.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbPcLEyxA9mL",
        "outputId": "2d97a49b-43e1-4d17-89fc-588a78327182"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20, 22, 24, 26, 28, 30]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtenga una lista compuesta por los numeros pares en el intervalo [20;30] y sus respectivas raices cuadradas.\n",
        "pares_rdd = sc.parallelize(range(20, 31)).filter(lambda x: x % 2 == 0)\n",
        "pares_y_sqrt_rdd = pares_rdd.flatMap(lambda x: [x, x ** 0.5])\n",
        "resultado = pares_y_sqrt_rdd.collect()\n",
        "pares_y_sqrt_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-HhrPTYAVPM",
        "outputId": "519e3ac8-08dc-4ad2-ac03-532e8260d8c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 4.47213595499958,\n",
              " 22,\n",
              " 4.69041575982343,\n",
              " 24,\n",
              " 4.898979485566356,\n",
              " 26,\n",
              " 5.0990195135927845,\n",
              " 28,\n",
              " 5.291502622129181,\n",
              " 30,\n",
              " 5.477225575051661]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Eleve el numero de particiones de RDD sqrt a 20\n",
        "pares_rdd = sc.parallelize(range(20, 31)).filter(lambda x: x % 2 == 0)\n",
        "pares_y_sqrt_rdd = pares_rdd.flatMap(lambda x: [x, x ** 0.5])\n",
        "pares_y_sqrt_rdd = pares_y_sqrt_rdd.repartition(20) #pares_y_sqrt_rdd = pares_y_sqrt_rdd.coalesce(10) con este codigo bajo las particiones de 20 a 10\n",
        "pares_y_sqrt_rdd.glom().collect()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XYl3RsiCBvY",
        "outputId": "9b48687e-e803-460c-c2c5-ba0748894016"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [26, 5.0990195135927845, 28, 5.291502622129181, 30, 5.477225575051661],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [20, 4.47213595499958, 22, 4.69041575982343, 24, 4.898979485566356],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Crea un RDD del tipo clave valor a partir de los datos adjuntos como recurso a esta leccion.\n",
        "#tenga en cuenta que debera procesar el RDD leido para obtener el resultado solicitado. Supongamos que el RDD resultante\n",
        "#de tipo clave valor refleja las transacciones realizadas por numero de cuentas . Obtenga el monto total por cada cuenta\n",
        "#tip cree su propia funcion para procesar el RDD leido.\n",
        "# Instalar findspark\n",
        "!pip install findspark\n",
        "# Importar findspark y SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Crear una SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"datos_transacciones\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Crear una lista de tuplas con los datos de transacciones\n",
        "datos_transacciones = [\n",
        "    (104301, 52.3),\n",
        "    (103305, 20.8),\n",
        "    (102301, 10.1),\n",
        "    (103004, 52.7),\n",
        "    (108305, 20.7),\n",
        "    (101302, 85.3),\n",
        "    (103342, 20.9)\n",
        "]\n",
        "\n",
        "rdd_transacciones = spark.sparkContext.parallelize(datos_transacciones)\n",
        "rdd_transacciones.collect()\n",
        "RDD_CUENTATOTAL = rdd_transacciones.reduceByKey(lambda x, y: x + y)\n",
        "RDD_CUENTATOTAL.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBg-bWNbEAYr",
        "outputId": "6bdeb97a-4fa9-46bd-e381-440c7d0ba58e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(103004, 52.7),\n",
              " (101302, 85.3),\n",
              " (103342, 20.9),\n",
              " (104301, 52.3),\n",
              " (103305, 20.8),\n",
              " (102301, 10.1),\n",
              " (108305, 20.7)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmgU4_BFE_Uf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}